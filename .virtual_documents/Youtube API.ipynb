


#import needed packages 
from googleapiclient.discovery import build
import pandas as pd

# load keys from  environmental var
from dotenv import load_dotenv
import os


# Load .env file
load_dotenv()

# Retrieve the API key
api_key = os.getenv("API_KEY")
#print(api_key)  


#instantiate a client 
youtube = build('youtube', 'v3', developerKey=api_key)


#create crime keywords in lower case
crime_keywords = [
    "homicide", "murder", "killing", "manslaughter", "shooting",
    "sex abuse", "rape", "assault", "domestic violence", "gender violence",
    "assault with dangerous weapon", "aggravated assault", "attempted manslaughter", "battery",
    "robbery", "theft", "mugging", "stealing", "robbing",
    "burglary", "break in", "forced entry", "housebreaking", "tresspassing",
    "theft auto", "motor vehicle theft", "carjacking", "vehicle larceny",
    "theft other",
    "motor vehicle theft",
    "arson", "destruction of property", "set on fire"
]

#dc names 
dc_names = [
    "Washington DC", "Washington D.C.", "DC", "D.C.", "District of Columbia",
    "The District", "District", "Capital City", "The Capital",
]




# Function to search for videos
def search_youtube(query):
    request = youtube.search().list(
        part="snippet",
        q=query,
        type="video",
        maxResults=10  # Number of results to return (can be adjusted)
    )
    response = request.execute()
    return response['items']

# Function to get video details (like count, view count)
def get_video_details(video_id):
    request = youtube.videos().list(
        part="statistics",
        id=video_id
    )
    response = request.execute()
    return response['items'][0]['statistics']

# Loop over each combination of dc_names and crime_keywords
def scrape_videos():
    all_videos = []
    
    for dc_name in dc_names:
        for crime_keyword in crime_keywords:
            query = f"{dc_name} {crime_keyword}"
            print(f"Searching for: {query}")
            videos = search_youtube(query)
            
            for video in videos:
                video_id = video['id']['videoId']
                stats = get_video_details(video_id)
                
                # Only keep videos with more than 100 views (change from likes to views)
                view_count = int(stats.get('viewCount', 0))
                if view_count > 100:
                    video['views'] = view_count  # Add view count to the video data
                    all_videos.append(video)
            
            # Stop if we've reached 100 videos
            if len(all_videos) >= 100:
                break
        if len(all_videos) >= 100:
            break
    
    return all_videos[:100]  # Limit to 100 videos



# Function to get video details (like count, view count, description, comments, and publication date)
def get_video_details(video_id):
    request = youtube.videos().list(
        part="snippet,statistics",  # 'snippet' for description, 'statistics' for views, comments, etc.
        id=video_id
    )
    response = request.execute()
    video_data = response['items'][0]
    
    # Extract relevant details
    stats = video_data['statistics']
    snippet = video_data['snippet']
    
    video_details = {
        'viewCount': int(stats.get('viewCount', 0)),
        'commentCount': int(stats.get('commentCount', 0)),
        'description': snippet.get('description', ''),
        'publishedAt': snippet.get('publishedAt', ''),
        'likeCount': int(stats.get('likeCount', 0)),
    }
    
    return video_details

# Scrape and store results in DataFrame
def scrape_videos_to_df():
    all_videos_data = []
    
    videos = scrape_videos()  # Call the scrape_videos function
    
    for video in videos:
        title = video['snippet']['title']
        video_id = video['id']['videoId']
        
        # Get additional video details
        video_details = get_video_details(video_id)
        
        # Collecting video data into a dictionary
        video_data = {
            'Title': title,
            'URL': f"https://www.youtube.com/watch?v={video_id}",
            'Likes': video_details['likeCount'],
            'Views': video_details['viewCount'],
            'Comments': video_details['commentCount'],
            'Description': video_details['description'],
            'Published At': video_details['publishedAt']
        }
        
        # Add the video data to the list
        all_videos_data.append(video_data)
    
    # Convert the list of dictionaries to a DataFrame
    yt_crime_data = pd.DataFrame(all_videos_data)
    
    return yt_crime_data

# Get the data and display it
yt_crime_data = scrape_videos_to_df()

# Print the DataFrame (optional)
print(yt_crime_data)


# Function to get video details (like count, view count, description, comments, and publication date, plus channel info)
def get_video_details(video_id):
    request = youtube.videos().list(
        part="snippet,statistics",  # 'snippet' for description, 'statistics' for views, comments, etc.
        id=video_id
    )
    response = request.execute()
    video_data = response['items'][0]
    
    # Extract relevant details
    stats = video_data['statistics']
    snippet = video_data['snippet']
    
    # Include channel details
    video_details = {
        'viewCount': int(stats.get('viewCount', 0)),
        'commentCount': int(stats.get('commentCount', 0)),
        'description': snippet.get('description', ''),
        'publishedAt': snippet.get('publishedAt', ''),
        'likeCount': int(stats.get('likeCount', 0)),
        'channelId': snippet.get('channelId', ''),  # Channel ID
        'channelTitle': snippet.get('channelTitle', '')  # Channel Title
    }
    
    return video_details



# Scrape and store results in DataFrame
def scrape_videos_to_df():
    all_videos_data = []
    
    videos = scrape_videos()  # Call the scrape_videos function
    
    for video in videos:
        title = video['snippet']['title']
        video_id = video['id']['videoId']
        
        # Get additional video details (including channel info)
        video_details = get_video_details(video_id)
        
        # Collecting video data into a dictionary
        video_data = {
            'Title': title,
            'URL': f"https://www.youtube.com/watch?v={video_id}",
            'Likes': video_details['likeCount'],
            'Views': video_details['viewCount'],
            'Comments Count': video_details['commentCount'],
            'Description': video_details['description'],
            'Published At': video_details['publishedAt'],
            'Channel ID': video_details['channelId'],  # Channel ID
            'Channel Title': video_details['channelTitle']  # Channel Title
        }
        
        # Add the video data to the list
        all_videos_data.append(video_data)
    
    # Convert the list of dictionaries to a DataFrame
    yt_crime_data = pd.DataFrame(all_videos_data)
    
    return yt_crime_data
# Get the data and display it
yt_crime_data = scrape_videos_to_df()

# Print the DataFrame (optional)
print(yt_crime_data)


# Save the DataFrame to a CSV file
yt_crime_data.to_csv('yt_crime_data.csv', index=False)



