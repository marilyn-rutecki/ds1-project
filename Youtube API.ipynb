{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a11510d-c8c8-441f-93f7-de843df891ec",
   "metadata": {},
   "source": [
    "#### Youtube API Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bdc242b-5470-49a2-87bc-b0626ee67a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import needed packages \n",
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n",
    "\n",
    "# load keys from  environmental var\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a544c9d-f45b-42f1-8d7b-806895a8e0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve the API key\n",
    "#api_key = os.getenv(\"API_KEY\")\n",
    "#second API key \n",
    "api_key = os.getenv(\"API_KEY2\")\n",
    "#third API key \n",
    "#api_key = os.getenv(\"API_KEY3\")\n",
    "#print(api_key)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "933569f9-ad58-4cf4-9a38-bc9812c7041c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate a client \n",
    "youtube = build('youtube', 'v3', developerKey=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c14f3582-54ad-4ae5-bd1d-bb714b549f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create crime keywords in lower case\n",
    "crime_keywords = [\n",
    "    \"homicide\", \"murder\", \"killing\", \"manslaughter\", \"shooting\",\n",
    "    \"sex abuse\", \"rape\", \"assault\", \"domestic violence\", \"gender violence\",\n",
    "    \"assault with dangerous weapon\", \"aggravated assault\", \"attempted manslaughter\", \"battery\",\n",
    "    \"robbery\", \"theft\", \"mugging\", \"stealing\", \"robbing\",\n",
    "    \"burglary\", \"break in\", \"forced entry\", \"housebreaking\", \"tresspassing\",\n",
    "    \"theft auto\", \"motor vehicle theft\", \"carjacking\", \"vehicle larceny\",\n",
    "    \"theft other\",\n",
    "    \"motor vehicle theft\",\n",
    "    \"arson\", \"destruction of property\", \"set on fire\"\n",
    "]\n",
    "\n",
    "#dc names \n",
    "dc_names = [\n",
    "    \"Washington DC\", \"Washington D.C.\", \"DC\", \"D.C.\", \"District of Columbia\",\n",
    "    \"The District\", \"District\", \"Capital City\", \"The Capital\",\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d26fc81a-18bb-4d83-81b2-70d7a88a2d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import time\n",
    "\n",
    "# Function to search for videos (with pagination support and delay)\n",
    "def search_youtube(query):\n",
    "    all_videos = []\n",
    "    next_page_token = None\n",
    "\n",
    "    while len(all_videos) < 500:  # Adjust the limit to 5,000 videos\n",
    "        request = youtube.search().list(\n",
    "            part=\"snippet\",\n",
    "            q=query,\n",
    "            type=\"video\",\n",
    "            maxResults=50,  # Max allowed per request\n",
    "            pageToken=next_page_token  # Token for the next page\n",
    "        )\n",
    "        response = request.execute()\n",
    "\n",
    "        # Add videos from the current page to the list\n",
    "        all_videos.extend(response['items'])\n",
    "\n",
    "        # Check if there's another page\n",
    "        next_page_token = response.get('nextPageToken')\n",
    "        if not next_page_token:\n",
    "            break  # Exit if there are no more pages\n",
    "\n",
    "       # time.sleep(1)  # Add a 1-second delay between requests to avoid rate limits\n",
    "\n",
    "    return all_videos[:500]  # Limit to 5,000 videos\n",
    "\n",
    "# Function to get video details (like count, view count)\n",
    "#def get_video_details(video_id):\n",
    "   # request = youtube.videos().list(\n",
    "   #     part=\"statistics\",\n",
    "   #     id=video_id\n",
    "   # )\n",
    "   # response = request.execute()\n",
    "    #return response['items'][0]['statistics']\n",
    "\n",
    "# Loop over each combination of dc_names and crime_keywords\n",
    "def scrape_videos():\n",
    "    all_videos = []\n",
    "    \n",
    "    for dc_name in dc_names:\n",
    "        for crime_keyword in crime_keywords:\n",
    "            query = f\"{dc_name} {crime_keyword}\"\n",
    "            print(f\"Searching for: {query}\")\n",
    "            videos = search_youtube(query)\n",
    "            \n",
    "            for video in videos:\n",
    "                video_id = video['id']['videoId']\n",
    "                stats = get_video_details(video_id)\n",
    "                \n",
    "                # Only keep videos with more than 100 views\n",
    "                view_count = int(stats.get('viewCount', 0))\n",
    "                if view_count > 100:\n",
    "                    video['views'] = view_count  # Add view count to the video data\n",
    "                    all_videos.append(video)\n",
    "            \n",
    "            # Stop if we've reached 500 videos\n",
    "            if len(all_videos) >= 500:\n",
    "                break\n",
    "        if len(all_videos) >= 500:\n",
    "            break\n",
    "    \n",
    "    return all_videos[:500]  # Limit to 500 videos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c201ad8f-50d1-4594-9ce3-e3bd05eeeca2",
   "metadata": {},
   "source": [
    "#### Function to get the video details "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c86f8a15-4340-4ffd-8c2b-0a39506147e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get video details (like count, view count, description, comments, and publication date, plus channel info)\n",
    "def get_video_details(video_id):\n",
    "    request = youtube.videos().list(\n",
    "        part=\"snippet,statistics\",  \n",
    "        id=video_id\n",
    "    )\n",
    "    response = request.execute()\n",
    "    video_data = response['items'][0]\n",
    "    \n",
    "    # Extract relevant details\n",
    "    stats = video_data['statistics']\n",
    "    snippet = video_data['snippet']\n",
    "    \n",
    "    # Include channel details\n",
    "    video_details = {\n",
    "        'viewCount': int(stats.get('viewCount', 0)),\n",
    "        'commentCount': int(stats.get('commentCount', 0)),\n",
    "        'description': snippet.get('description', ''),\n",
    "        'publishedAt': snippet.get('publishedAt', ''),\n",
    "        'likeCount': int(stats.get('likeCount', 0)),\n",
    "        'channelId': snippet.get('channelId', ''),  # Channel ID\n",
    "        'channelTitle': snippet.get('channelTitle', '')  # Channel Title\n",
    "    }\n",
    "    \n",
    "    return video_details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8cb6b8aa-88e9-4659-b8e7-7837de0af148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for: Washington DC homicide\n",
      "Searching for: Washington DC murder\n",
      "                                                 Title  \\\n",
      "0                 Inside the DC Mansion Murders (2015)   \n",
      "1                       Suspects wanted in DC homicide   \n",
      "2        DC Police search for suspect in homicide case   \n",
      "3    D.C.&#39;s First Female Homicide Detective Unc...   \n",
      "4    32-year-old mother, special police officer ide...   \n",
      "..                                                 ...   \n",
      "495  32-year-old mother, special police officer ide...   \n",
      "496       DC Mansion Murder Suspect Taken Into Custody   \n",
      "497        Suspect on the run after Foot Locker murder   \n",
      "498  Video captures moments before mom allegedly sh...   \n",
      "499     Why violent crime is rising in Washington D.C.   \n",
      "\n",
      "                                             URL  Likes    Views  \\\n",
      "0    https://www.youtube.com/watch?v=wfcN2iaE2vE  13918  1552574   \n",
      "1    https://www.youtube.com/watch?v=SDoOr39lAV0      1      278   \n",
      "2    https://www.youtube.com/watch?v=H3Au26Fws64      8     1709   \n",
      "3    https://www.youtube.com/watch?v=dw4exHCv5fY   1416    50092   \n",
      "4    https://www.youtube.com/watch?v=CmGtq06J7ik     21     1902   \n",
      "..                                           ...    ...      ...   \n",
      "495  https://www.youtube.com/watch?v=CmGtq06J7ik     21     1902   \n",
      "496  https://www.youtube.com/watch?v=BurZd0x3TH4   3702   894368   \n",
      "497  https://www.youtube.com/watch?v=jIVCbUFh_ys    474    47547   \n",
      "498  https://www.youtube.com/watch?v=OACfwtuaYN4   8150   733770   \n",
      "499  https://www.youtube.com/watch?v=pKO6G0euino    199    19006   \n",
      "\n",
      "     Comments Count                                        Description  \\\n",
      "0              1510  CNN's Pamela Brown speaks with investigators a...   \n",
      "1                 0  D.C. police are looking for two people who the...   \n",
      "2                 6  Police are searching for a suspect connected t...   \n",
      "3               107  Romaine Jenkins investigated many horrifying c...   \n",
      "4                 2  On Monday, investigators say 32-year-old Cynth...   \n",
      "..              ...                                                ...   \n",
      "495               2  On Monday, investigators say 32-year-old Cynth...   \n",
      "496            1137  DNA on a pizza crust led police to naming Daro...   \n",
      "497             330  The search is on for a third suspect after a m...   \n",
      "498            1759  A 13-year-old girl is fighting for her life af...   \n",
      "499             179  The House Administration Committee is being br...   \n",
      "\n",
      "             Published At                Channel ID        Channel Title  \n",
      "0    2024-02-10T23:00:28Z  UCupvZG-5ko_eiXAupbDfxWw                  CNN  \n",
      "1    2024-09-18T20:56:10Z  UCP3sSdrcCw7qC0qSrD8xOHQ          DC News Now  \n",
      "2    2023-10-15T03:21:37Z  UCcT6w3xUyVshyR2_2vrMp1w                WUSA9  \n",
      "3    2024-07-12T19:00:27Z  UCNIFiHaLZkYASaWDdkC1njg                  A&E  \n",
      "4    2021-11-02T03:38:10Z  UCcT6w3xUyVshyR2_2vrMp1w                WUSA9  \n",
      "..                    ...                       ...                  ...  \n",
      "495  2021-11-02T03:38:10Z  UCcT6w3xUyVshyR2_2vrMp1w                WUSA9  \n",
      "496  2015-05-22T06:48:26Z  UCBi2mrWuNuyYy4gbM6fU18Q             ABC News  \n",
      "497  2024-10-11T21:34:38Z  UCHLyP4MuA-JAFBCwxXOEDdA  FOX 5 Washington DC  \n",
      "498  2024-09-25T02:39:45Z  UCHLyP4MuA-JAFBCwxXOEDdA  FOX 5 Washington DC  \n",
      "499  2023-09-18T20:53:32Z  UC8p1vwvWtl6T73JiExfWs1g             CBS News  \n",
      "\n",
      "[500 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# Scrape and store results in DataFrame\n",
    "#create a function that scrape and stores the vidoes into a dataframe \n",
    "def scrape_videos_to_df():\n",
    "    all_videos_data = []\n",
    "      # Call the scrape_videos function\n",
    "    videos = scrape_videos()\n",
    "    \n",
    "    for video in videos:\n",
    "        title = video['snippet']['title']\n",
    "        video_id = video['id']['videoId']\n",
    "        \n",
    "        # Get additional video details \n",
    "        video_details = get_video_details(video_id)\n",
    "        \n",
    "        # Collecting video data into a dictionary\n",
    "        video_data = {\n",
    "            'Title': title,\n",
    "            'URL': f\"https://www.youtube.com/watch?v={video_id}\",\n",
    "            'Likes': video_details['likeCount'],\n",
    "            'Views': video_details['viewCount'],\n",
    "            'Comments Count': video_details['commentCount'],\n",
    "            'Description': video_details['description'],\n",
    "            'Published At': video_details['publishedAt'],\n",
    "            'Channel ID': video_details['channelId'],  \n",
    "            'Channel Title': video_details['channelTitle'] \n",
    "        }\n",
    "        \n",
    "        # Add the video data to the list\n",
    "        all_videos_data.append(video_data)\n",
    "    \n",
    "    # Convert the list of dictionaries to a DataFrame\n",
    "    yt_crime_data = pd.DataFrame(all_videos_data)\n",
    "    \n",
    "    return yt_crime_data\n",
    "# Get the data and display it\n",
    "yt_crime_data = scrape_videos_to_df()\n",
    "\n",
    "# Print the DataFrame (optional)\n",
    "print(yt_crime_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2341f589-fe56-4223-9667-e86da997f93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "yt_crime_data.to_csv('yt_crime_data_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dd4aa8-5705-4ba0-a7df-29bad1059d92",
   "metadata": {},
   "source": [
    "#### Running the function multiple times to scrape 500 videos per scrape because Youtube has a token limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c8aeb36-11e5-4752-99e8-8e15cd45260b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for: Washington DC homicide\n",
      "Searching for: Washington DC murder\n",
      "                                                 Title  \\\n",
      "0                 Inside the DC Mansion Murders (2015)   \n",
      "1                       Suspects wanted in DC homicide   \n",
      "2        DC Police search for suspect in homicide case   \n",
      "3    32-year-old mother, special police officer ide...   \n",
      "4    D.C.&#39;s First Female Homicide Detective Unc...   \n",
      "..                                                 ...   \n",
      "495                    3 dead in multiple DC shootings   \n",
      "496  Still questions in unsolved murder in young wo...   \n",
      "497  Two Men Arrested in DC Murder of Memphis Rappe...   \n",
      "498  Suspect in DC Hotel Homicide Had Lengthy Crimi...   \n",
      "499  DC Police identify suspect in murder case wher...   \n",
      "\n",
      "                                             URL  Likes    Views  \\\n",
      "0    https://www.youtube.com/watch?v=wfcN2iaE2vE  13918  1552637   \n",
      "1    https://www.youtube.com/watch?v=SDoOr39lAV0      1      280   \n",
      "2    https://www.youtube.com/watch?v=H3Au26Fws64      8     1709   \n",
      "3    https://www.youtube.com/watch?v=CmGtq06J7ik     21     1902   \n",
      "4    https://www.youtube.com/watch?v=dw4exHCv5fY   1416    50096   \n",
      "..                                           ...    ...      ...   \n",
      "495  https://www.youtube.com/watch?v=uoxncSc1c5c    143    16463   \n",
      "496  https://www.youtube.com/watch?v=yZkq3AU-42k     13     2132   \n",
      "497  https://www.youtube.com/watch?v=jdEypBZLIeQ    393    79327   \n",
      "498  https://www.youtube.com/watch?v=kaoiw7_RA9Y    105     8181   \n",
      "499  https://www.youtube.com/watch?v=juHCzPxZKME     94    18011   \n",
      "\n",
      "     Comments Count                                        Description  \\\n",
      "0              1510  CNN's Pamela Brown speaks with investigators a...   \n",
      "1                 0  D.C. police are looking for two people who the...   \n",
      "2                 6  Police are searching for a suspect connected t...   \n",
      "3                 2  On Monday, investigators say 32-year-old Cynth...   \n",
      "4               107  Romaine Jenkins investigated many horrifying c...   \n",
      "..              ...                                                ...   \n",
      "495              47  It's been a violent start to the week in the D...   \n",
      "496               0         The young victim wanted to be a detective.   \n",
      "497             110  Police are offering a reward of up to $25,000 ...   \n",
      "498             112  A 31-year-old Virginia woman was stabbed more ...   \n",
      "499              39  DC Police have identified a suspect in a murde...   \n",
      "\n",
      "             Published At                Channel ID        Channel Title  \n",
      "0    2024-02-10T23:00:28Z  UCupvZG-5ko_eiXAupbDfxWw                  CNN  \n",
      "1    2024-09-18T20:56:10Z  UCP3sSdrcCw7qC0qSrD8xOHQ          DC News Now  \n",
      "2    2023-10-15T03:21:37Z  UCcT6w3xUyVshyR2_2vrMp1w                WUSA9  \n",
      "3    2021-11-02T03:38:10Z  UCcT6w3xUyVshyR2_2vrMp1w                WUSA9  \n",
      "4    2024-07-12T19:00:27Z  UCNIFiHaLZkYASaWDdkC1njg                  A&E  \n",
      "..                    ...                       ...                  ...  \n",
      "495  2024-10-08T10:02:13Z  UCHLyP4MuA-JAFBCwxXOEDdA  FOX 5 Washington DC  \n",
      "496  2018-03-07T23:25:12Z  UCcT6w3xUyVshyR2_2vrMp1w                WUSA9  \n",
      "497  2022-03-03T22:24:17Z  UC1VKVKhJLc7PjdPPVxTDk0Q      NBC4 Washington  \n",
      "498  2023-04-04T00:48:54Z  UC1VKVKhJLc7PjdPPVxTDk0Q      NBC4 Washington  \n",
      "499  2022-03-17T17:35:59Z  UCHLyP4MuA-JAFBCwxXOEDdA  FOX 5 Washington DC  \n",
      "\n",
      "[500 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# scraping the next 500 videos and appending to the csv file \n",
    "def scrape_videos_to_df():\n",
    "    # Load the existing data from the CSV file\n",
    "    try:\n",
    "        yt_crime_data = pd.read_csv('yt-crime_data_2.csv')\n",
    "    except FileNotFoundError:\n",
    "        # If the file doesn't exist, start with an empty DataFrame\n",
    "        yt_crime_data = pd.DataFrame()  \n",
    "    \n",
    "    # Extract existing video IDs from the CSV\n",
    "    existing_video_ids = yt_crime_data['URL'].apply(lambda x: x.split('v=')[-1]).tolist() if not yt_crime_data.empty else []\n",
    "    \n",
    "    all_videos_data = []\n",
    "    \n",
    "    # Call the scrape_videos function to get new videos\n",
    "    videos = scrape_videos()\n",
    "    \n",
    "    for video in videos:\n",
    "        video_id = video['id']['videoId']\n",
    "        \n",
    "        # Skip videos that are already in the CSV file (by checking the video ID)\n",
    "        if video_id in existing_video_ids:\n",
    "            continue\n",
    "        \n",
    "        # Get additional video details\n",
    "        video_details = get_video_details(video_id)\n",
    "        \n",
    "        # Collecting video data into a dictionary\n",
    "        video_data = {\n",
    "            'Title': video['snippet']['title'],\n",
    "            'URL': f\"https://www.youtube.com/watch?v={video_id}\",\n",
    "            'Likes': video_details['likeCount'],\n",
    "            'Views': video_details['viewCount'],\n",
    "            'Comments Count': video_details['commentCount'],\n",
    "            'Description': video_details['description'],\n",
    "            'Published At': video_details['publishedAt'],\n",
    "            'Channel ID': video_details['channelId'],\n",
    "            'Channel Title': video_details['channelTitle']  \n",
    "        }\n",
    "        \n",
    "        # Add the video data to the list\n",
    "        all_videos_data.append(video_data)\n",
    "    \n",
    "    # Convert the list of dictionaries to a DataFrame\n",
    "    new_videos_data = pd.DataFrame(all_videos_data)\n",
    "    \n",
    "    # If there are new videos, append them to the existing CSV file\n",
    "    if not new_videos_data.empty:\n",
    "        yt_crime_data = pd.concat([yt_crime_data, new_videos_data], ignore_index=True)\n",
    "        yt_crime_data.to_csv('yt-crime_data_2.csv', index=False)  # Save the updated DataFrame to the CSV file\n",
    "    \n",
    "    return yt_crime_data\n",
    "\n",
    "# Get the updated data and display it\n",
    "yt_crime_data = scrape_videos_to_df()\n",
    "\n",
    "# Print the updated DataFrame (optional)\n",
    "print(yt_crime_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f37296-fae3-4b1f-80a9-ba19936b9b73",
   "metadata": {},
   "source": [
    "#### Repeat the same procedure as above to get the next 500 videos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27be95ad-e431-47e9-966f-2dc2abb26c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for: Washington DC homicide\n",
      "Searching for: Washington DC murder\n",
      "                                                 Title  \\\n",
      "0                 Inside the DC Mansion Murders (2015)   \n",
      "1                       Suspects wanted in DC homicide   \n",
      "2        DC Police search for suspect in homicide case   \n",
      "3    32-year-old mother, special police officer ide...   \n",
      "4    D.C.&#39;s First Female Homicide Detective Unc...   \n",
      "..                                                 ...   \n",
      "617  Man Charged In Murder Of D.C. Jogger | NBC Nig...   \n",
      "618                 D.C. Mansion Murder Suspect Caught   \n",
      "619  DC man charged with murder in shooting death o...   \n",
      "620  DC Police Sergeant charged with second-degree ...   \n",
      "621  Murder victim&#39;s grandmother angry at DC po...   \n",
      "\n",
      "                                             URL  Likes    Views  \\\n",
      "0    https://www.youtube.com/watch?v=wfcN2iaE2vE  13918  1552637   \n",
      "1    https://www.youtube.com/watch?v=SDoOr39lAV0      1      280   \n",
      "2    https://www.youtube.com/watch?v=H3Au26Fws64      8     1709   \n",
      "3    https://www.youtube.com/watch?v=CmGtq06J7ik     21     1902   \n",
      "4    https://www.youtube.com/watch?v=dw4exHCv5fY   1416    50096   \n",
      "..                                           ...    ...      ...   \n",
      "617  https://www.youtube.com/watch?v=5Jhzt6MvtHQ     35     7685   \n",
      "618  https://www.youtube.com/watch?v=_sOGk_8dgH0     39    13176   \n",
      "619  https://www.youtube.com/watch?v=laDb790COag      2      611   \n",
      "620  https://www.youtube.com/watch?v=LfwYZwUaR7Y     19     3956   \n",
      "621  https://www.youtube.com/watch?v=mEndwKKlcuU     23     3338   \n",
      "\n",
      "     Comments Count                                        Description  \\\n",
      "0              1510  CNN's Pamela Brown speaks with investigators a...   \n",
      "1                 0  D.C. police are looking for two people who the...   \n",
      "2                 6  Police are searching for a suspect connected t...   \n",
      "3                 2  On Monday, investigators say 32-year-old Cynth...   \n",
      "4               107  Romaine Jenkins investigated many horrifying c...   \n",
      "..              ...                                                ...   \n",
      "617              30  Police say the 23-year-old man stabbed tech ex...   \n",
      "618               9  After a week on the run, Daron Wint was arrest...   \n",
      "619               0  Police say 31-year-old Tyriq Williams of North...   \n",
      "620               8  An MPD Sergeant has been charged with second-d...   \n",
      "621               3  A nightmare came true for a D.C. family as a m...   \n",
      "\n",
      "             Published At                Channel ID Channel Title  \n",
      "0    2024-02-10T23:00:28Z  UCupvZG-5ko_eiXAupbDfxWw           CNN  \n",
      "1    2024-09-18T20:56:10Z  UCP3sSdrcCw7qC0qSrD8xOHQ   DC News Now  \n",
      "2    2023-10-15T03:21:37Z  UCcT6w3xUyVshyR2_2vrMp1w         WUSA9  \n",
      "3    2021-11-02T03:38:10Z  UCcT6w3xUyVshyR2_2vrMp1w         WUSA9  \n",
      "4    2024-07-12T19:00:27Z  UCNIFiHaLZkYASaWDdkC1njg           A&E  \n",
      "..                    ...                       ...           ...  \n",
      "617  2018-09-20T23:53:22Z  UCeY0bbntWzzVIaj2z3QigXg      NBC News  \n",
      "618  2015-05-22T07:44:02Z  UCBi2mrWuNuyYy4gbM6fU18Q      ABC News  \n",
      "619  2023-01-20T22:18:06Z  UCcT6w3xUyVshyR2_2vrMp1w         WUSA9  \n",
      "620  2023-03-07T22:34:51Z  UCcT6w3xUyVshyR2_2vrMp1w         WUSA9  \n",
      "621  2018-01-11T23:23:48Z  UCcT6w3xUyVshyR2_2vrMp1w         WUSA9  \n",
      "\n",
      "[622 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# scrape and add to existing csv file \n",
    "def scrape_videos_to_df(filename='yt-crime_data_2.csv'):\n",
    "    #Load the existing data from the CSV file\n",
    "    try:\n",
    "        yt_crime_data = pd.read_csv(filename)\n",
    "    except FileNotFoundError:\n",
    "        yt_crime_data = pd.DataFrame()  # If the file doesn't exist, start with an empty DataFrame\n",
    "    \n",
    "    #Extract existing video IDs from the 'URL' column \n",
    "    existing_video_ids = yt_crime_data['URL'].apply(lambda x: x.split('v=')[-1]).tolist() if not yt_crime_data.empty else []\n",
    "\n",
    "    # Initialize a list to store new video data\n",
    "    all_videos_data = []\n",
    "\n",
    "    # Call the scrape_videos function to get new videos\n",
    "    videos = scrape_videos()  \n",
    "\n",
    "    # Loop through the scraped videos and check if they already exist in the DataFrame\n",
    "    for video in videos:\n",
    "        video_id = video['id']['videoId']\n",
    "\n",
    "        # Skip videos that are already in the CSV file (by checking the video ID)\n",
    "        if video_id in existing_video_ids:\n",
    "            continue\n",
    "\n",
    "        # Get additional video details (this assumes the get_video_details function is defined)\n",
    "        video_details = get_video_details(video_id)\n",
    "\n",
    "        # Collect video data into a dictionary\n",
    "        video_data = {\n",
    "            'Title': video['snippet']['title'],\n",
    "            'URL': f\"https://www.youtube.com/watch?v={video_id}\",\n",
    "            'Likes': video_details['likeCount'],\n",
    "            'Views': video_details['viewCount'],\n",
    "            'Comments Count': video_details['commentCount'],\n",
    "            'Description': video_details['description'],\n",
    "            'Published At': video_details['publishedAt'],\n",
    "            'Channel ID': video_details['channelId'], \n",
    "            'Channel Title': video_details['channelTitle'] \n",
    "        }\n",
    "\n",
    "        # Add the video data to the list\n",
    "        all_videos_data.append(video_data)\n",
    "\n",
    "    # Convert the list of dictionaries to a DataFrame\n",
    "    new_videos_data = pd.DataFrame(all_videos_data)\n",
    "\n",
    "    # If there are new videos, append them to the existing DataFrame and save to CSV\n",
    "    if not new_videos_data.empty:\n",
    "        yt_crime_data = pd.concat([yt_crime_data, new_videos_data], ignore_index=True)\n",
    "        # Save the updated DataFrame to the CSV file\n",
    "        yt_crime_data.to_csv(filename, index=False)  \n",
    "\n",
    "    return yt_crime_data\n",
    "\n",
    "# Get the updated data and display it\n",
    "yt_crime_data = scrape_videos_to_df('yt-crime_data_2.csv')\n",
    "\n",
    "# Print the updated DataFrame (optional)\n",
    "print(yt_crime_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4225b5-b8c2-4812-8041-a07fb23f4444",
   "metadata": {},
   "source": [
    "#### Scraping while handling pagination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc661261-9524-4053-8e0f-d99a768c71d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Title  \\\n",
      "0                 Inside the DC Mansion Murders (2015)   \n",
      "1                       Suspects wanted in DC homicide   \n",
      "2        DC Police search for suspect in homicide case   \n",
      "3    32-year-old mother, special police officer ide...   \n",
      "4    D.C.&#39;s First Female Homicide Detective Unc...   \n",
      "..                                                 ...   \n",
      "717                           üò¢„Äê2chÊÑüÂãï„Çπ„É¨„ÄëÊÑüÂãï„ÅÆËø∑Ë®ÄÈõÜÔΩû„ÉÅ„É£„ÉÉ„Ç´„Éû„É≥ÔΩû   \n",
      "718  Pudo ser el mejor delantero del mundo pero su ...   \n",
      "719              ÂÖÑ„ÅÆÁà™Âàá„Çä„ÇíË¶ã„Åü„Å†„Åë„ÅßÊãíÁµ∂ÂèçÂøú„ÇíËµ∑„Åì„Åó„ÅüÁå´„Åå„Å®„Çì„Åß„ÇÇ„Å™„ÅÑ„Åì„Å®„Å´„Å™„Çä„Åæ„Åó„Åü‚Ä¶   \n",
      "720  UNKNOWN SISTERS OF MUKESH AMBANI!!! #mukeshamb...   \n",
      "721                               üò¢„Äê2chÊÑüÂãï„Çπ„É¨„ÄëÊÑüÂãï„ÅÆËø∑Ë®ÄÈõÜÔΩûÁúüÁõ∏ÔΩû   \n",
      "\n",
      "                                             URL  Likes    Views  \\\n",
      "0    https://www.youtube.com/watch?v=wfcN2iaE2vE  13918  1552637   \n",
      "1    https://www.youtube.com/watch?v=SDoOr39lAV0      1      280   \n",
      "2    https://www.youtube.com/watch?v=H3Au26Fws64      8     1709   \n",
      "3    https://www.youtube.com/watch?v=CmGtq06J7ik     21     1902   \n",
      "4    https://www.youtube.com/watch?v=dw4exHCv5fY   1416    50096   \n",
      "..                                           ...    ...      ...   \n",
      "717  https://www.youtube.com/watch?v=lPAU8kdFOf8  23075   364029   \n",
      "718  https://www.youtube.com/watch?v=9k-X9vxY5HA      0  1365545   \n",
      "719  https://www.youtube.com/watch?v=UyLwaUlB3gQ      0   451199   \n",
      "720  https://www.youtube.com/watch?v=W0U0DjA5bVw  47690   594263   \n",
      "721  https://www.youtube.com/watch?v=bYN2EmDeeHA  15113   238608   \n",
      "\n",
      "     Comments Count                                        Description  \\\n",
      "0              1510  CNN's Pamela Brown speaks with investigators a...   \n",
      "1                 0  D.C. police are looking for two people who the...   \n",
      "2                 6  Police are searching for a suspect connected t...   \n",
      "3                 2  On Monday, investigators say 32-year-old Cynth...   \n",
      "4               107  Romaine Jenkins investigated many horrifying c...   \n",
      "..              ...                                                ...   \n",
      "717             298  Á∑®ÈõÜËÄÖÔºöYüçì\\n„Ç≥„É°„É≥„ÉàÔºöÊÑüÂãï„ÅßÊ∂ô„ÅåÊ∫¢„Çå„Çã‚Ä¶\\n‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\\n...   \n",
      "718             259                                                      \n",
      "719             791  ‚¨áÔ∏è„É°„É≥„Éê„Éº„Ç∑„ÉÉ„Éó„Å∏„ÅÆÂèÇÂä†„ÅØ„Åì„Å°„Çâ\\nhttps://www.youtube.com/@mo...   \n",
      "720             105  Mukesh Ambani has two sisters, but you might n...   \n",
      "721             135  Á∑®ÈõÜËÄÖÔºöKüíª\\n„Ç≥„É°„É≥„ÉàÔºöÊÑüÊÉÖ„ÅåÊ∫¢„Çå„Å¶Ê≠¢„Åæ„Çâ„Å™„ÅÑ‚Ä¶\\n‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî...   \n",
      "\n",
      "             Published At                Channel ID         Channel Title  \n",
      "0    2024-02-10T23:00:28Z  UCupvZG-5ko_eiXAupbDfxWw                   CNN  \n",
      "1    2024-09-18T20:56:10Z  UCP3sSdrcCw7qC0qSrD8xOHQ           DC News Now  \n",
      "2    2023-10-15T03:21:37Z  UCcT6w3xUyVshyR2_2vrMp1w                 WUSA9  \n",
      "3    2021-11-02T03:38:10Z  UCcT6w3xUyVshyR2_2vrMp1w                 WUSA9  \n",
      "4    2024-07-12T19:00:27Z  UCNIFiHaLZkYASaWDdkC1njg                   A&E  \n",
      "..                    ...                       ...                   ...  \n",
      "717  2024-12-03T12:01:03Z  UCrGE3psX4voLTkfiW9fualg  „ÄêÁ¨ë„Åà„Çã„Ç≥„Éî„ÉöÈÄ£Áô∫„Äë2ch„Ç∑„Éß„Éº„Éà„Åæ„Å®„ÇÅ  \n",
      "718  2024-12-03T18:59:46Z  UC6Dhs8ty7MsLENOTvTY2Idg             Jose Cobo  \n",
      "719  2024-12-04T11:01:20Z  UCplhkHsYKxXjTde1lq8F-4w                „ÇÇ„Å°„Åæ„ÇãÊó•Ë®ò  \n",
      "720  2024-12-03T17:26:29Z  UCHvKJ6u9t9weize9wSSwbBQ       Prabhjot Speaks  \n",
      "721  2024-12-03T11:00:48Z  UCrGE3psX4voLTkfiW9fualg  „ÄêÁ¨ë„Åà„Çã„Ç≥„Éî„ÉöÈÄ£Áô∫„Äë2ch„Ç∑„Éß„Éº„Éà„Åæ„Å®„ÇÅ  \n",
      "\n",
      "[722 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#get 500 more views with pagination\n",
    "# Function to handle YouTube video scraping with pagination\n",
    "def scrape_videos_with_pagination(max_results=600):\n",
    "    # Initialize an empty list to store the video results\n",
    "    all_videos = []\n",
    "    \n",
    "    # Define the initial API request parameters\n",
    "    next_page_token = None  # Start with no page token\n",
    "    results_fetched = 0  # Keep track of how many results we've fetched\n",
    "    \n",
    "    while results_fetched < max_results:\n",
    "        # Make the API request with the nextPageToken for pagination\n",
    "        search_response = youtube.search().list(\n",
    "            part=\"snippet\",\n",
    "            maxResults=50,  # Maximum results per page\n",
    "            pageToken=next_page_token  # Token to fetch the next page\n",
    "        ).execute()\n",
    "        \n",
    "        # Append the fetched videos to the list\n",
    "        all_videos.extend(search_response['items'])\n",
    "        results_fetched += len(search_response['items'])  # Count how many we've fetched\n",
    "        \n",
    "        # Check if there's a next page\n",
    "        next_page_token = search_response.get('nextPageToken')\n",
    "        \n",
    "        # If no nextPageToken, we've reached the end of the results\n",
    "        if not next_page_token:\n",
    "            break\n",
    "\n",
    "    return all_videos\n",
    "\n",
    "def scrape_videos_to_df(filename='yt-crime_data_2.csv'):\n",
    "    # Load the existing data from the CSV file\n",
    "    try:\n",
    "        yt_crime_data = pd.read_csv(filename)\n",
    "    except FileNotFoundError:\n",
    "          # If the file doesn't exist, start with an empty DataFrame\n",
    "        yt_crime_data = pd.DataFrame()\n",
    "    \n",
    "    # Extract existing video IDs from the 'URL' column \n",
    "    existing_video_ids = yt_crime_data['URL'].apply(lambda x: x.split('v=')[-1]).tolist() if not yt_crime_data.empty else []\n",
    "\n",
    "    # Initialize a list to store new video data\n",
    "    all_videos_data = []\n",
    "\n",
    "    # Call the scrape_videos_with_pagination function to get new videos\n",
    "    videos = scrape_videos_with_pagination(max_results=600) \n",
    "\n",
    "    # Loop through the scraped videos and check if they already exist in the DataFrame\n",
    "    for video in videos:\n",
    "        # Check if 'id' and 'videoId' are present in the video object\n",
    "        if 'id' in video and 'videoId' in video['id']:\n",
    "            video_id = video['id']['videoId']\n",
    "        else:\n",
    "            # Skip videos that don't have a valid 'videoId'\n",
    "            continue\n",
    "\n",
    "        # Skip videos that are already in the CSV file (by checking the video ID)\n",
    "        if video_id in existing_video_ids:\n",
    "            continue\n",
    "\n",
    "        # Get additional video details \n",
    "        video_details = get_video_details(video_id)\n",
    "\n",
    "        # Collecting video data into a dictionary\n",
    "        video_data = {\n",
    "            'Title': video['snippet']['title'],\n",
    "            'URL': f\"https://www.youtube.com/watch?v={video_id}\",\n",
    "            'Likes': video_details['likeCount'],\n",
    "            'Views': video_details['viewCount'],\n",
    "            'Comments Count': video_details['commentCount'],\n",
    "            'Description': video_details['description'],\n",
    "            'Published At': video_details['publishedAt'],\n",
    "            'Channel ID': video_details['channelId'],  # Channel ID\n",
    "            'Channel Title': video_details['channelTitle']  # Channel Title\n",
    "        }\n",
    "\n",
    "        # Add the video data to the list\n",
    "        all_videos_data.append(video_data)\n",
    "\n",
    "    # Convert the list of dictionaries to a DataFrame\n",
    "    new_videos_data = pd.DataFrame(all_videos_data)\n",
    "\n",
    "    # append new vidoes to the existing DataFrame and save to CSV\n",
    "    if not new_videos_data.empty:\n",
    "        yt_crime_data = pd.concat([yt_crime_data, new_videos_data], ignore_index=True)\n",
    "        yt_crime_data.to_csv(filename, index=False)  # Save the updated DataFrame to the CSV file\n",
    "\n",
    "    return yt_crime_data\n",
    "\n",
    "# Get the updated data and display it\n",
    "yt_crime_data = scrape_videos_to_df('yt-crime_data_2.csv')\n",
    "\n",
    "# view the updated DataFrame\n",
    "print(yt_crime_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3fe0d7-7a5b-4cd3-a8ec-c7d8c3b96102",
   "metadata": {},
   "source": [
    "#### Get all videos including those with less than 100 views  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2439f508-c4b3-44cf-9bbf-5a09f74b6880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Title  \\\n",
      "0                 Inside the DC Mansion Murders (2015)   \n",
      "1                       Suspects wanted in DC homicide   \n",
      "2        DC Police search for suspect in homicide case   \n",
      "3    32-year-old mother, special police officer ide...   \n",
      "4    D.C.&#39;s First Female Homicide Detective Unc...   \n",
      "..                                                 ...   \n",
      "784  Liveüî¥Akhilesh Yadav ‡§∏‡§¶‡§® ‡§Æ‡•á‡§Ç Sambhal ‡§™‡§∞ ‡§¨‡•ã‡§≤‡•á ‡§π‡§ø...   \n",
      "785  Comprando a decora√ß√£o do meu quarto novo üå∏ü©∑ #v...   \n",
      "786  Me quede asi üëÅÔ∏èüëÑüëÅÔ∏è #minivlog #bakabakamx #lipg...   \n",
      "787          T√çPICAS TRAVESURAS DE HERMANOS: (PARTE 3)   \n",
      "788                CUANDO TE TOCA REPARTIDORA PREMIUM:   \n",
      "\n",
      "                                             URL   Likes    Views  \\\n",
      "0    https://www.youtube.com/watch?v=wfcN2iaE2vE   13918  1552637   \n",
      "1    https://www.youtube.com/watch?v=SDoOr39lAV0       1      280   \n",
      "2    https://www.youtube.com/watch?v=H3Au26Fws64       8     1709   \n",
      "3    https://www.youtube.com/watch?v=CmGtq06J7ik      21     1902   \n",
      "4    https://www.youtube.com/watch?v=dw4exHCv5fY    1416    50096   \n",
      "..                                           ...     ...      ...   \n",
      "784  https://www.youtube.com/watch?v=dlnOwHOmUrU     799  1321369   \n",
      "785  https://www.youtube.com/watch?v=I3OJonshtxE   63455  1120581   \n",
      "786  https://www.youtube.com/watch?v=8UuD1fssRzs  133366  1066524   \n",
      "787  https://www.youtube.com/watch?v=ZcK7YWy9PnE   78030  1544647   \n",
      "788  https://www.youtube.com/watch?v=9mCTc1xXyKI   89222  1788811   \n",
      "\n",
      "     Comments Count                                        Description  \\\n",
      "0              1510  CNN's Pamela Brown speaks with investigators a...   \n",
      "1                 0  D.C. police are looking for two people who the...   \n",
      "2                 6  Police are searching for a suspect connected t...   \n",
      "3                 2  On Monday, investigators say 32-year-old Cynth...   \n",
      "4               107  Romaine Jenkins investigated many horrifying c...   \n",
      "..              ...                                                ...   \n",
      "784               0  ?Hashtags :- #2024election #narendramodi #rahu...   \n",
      "785             291                                                      \n",
      "786             522                                                      \n",
      "787              32                             No olvides suscribirte   \n",
      "788              32                             No olvides suscribirte   \n",
      "\n",
      "             Published At                Channel ID  \\\n",
      "0    2024-02-10T23:00:28Z  UCupvZG-5ko_eiXAupbDfxWw   \n",
      "1    2024-09-18T20:56:10Z  UCP3sSdrcCw7qC0qSrD8xOHQ   \n",
      "2    2023-10-15T03:21:37Z  UCcT6w3xUyVshyR2_2vrMp1w   \n",
      "3    2021-11-02T03:38:10Z  UCcT6w3xUyVshyR2_2vrMp1w   \n",
      "4    2024-07-12T19:00:27Z  UCNIFiHaLZkYASaWDdkC1njg   \n",
      "..                    ...                       ...   \n",
      "784  2024-12-04T19:19:27Z  UCSV3FaYB43IqOScGl0N4LMw   \n",
      "785  2024-12-02T20:49:00Z  UCWxGghAvc6Nnu381Qq64ovQ   \n",
      "786  2024-12-03T01:50:35Z  UC-fUtoF04dbgezadoP_gG6g   \n",
      "787  2024-12-03T01:55:18Z  UCX-f1yDProbRQrsaVYgjvOQ   \n",
      "788  2024-12-02T02:20:32Z  UCX-f1yDProbRQrsaVYgjvOQ   \n",
      "\n",
      "                      Channel Title  \n",
      "0                               CNN  \n",
      "1                       DC News Now  \n",
      "2                             WUSA9  \n",
      "3                             WUSA9  \n",
      "4                               A&E  \n",
      "..                              ...  \n",
      "784                Hindustan 9 News  \n",
      "785  A ruiva da ro√ßa / Fabio Castro  \n",
      "786                    BAKA BAKA MX  \n",
      "787              Los Florezzz Gamez  \n",
      "788              Los Florezzz Gamez  \n",
      "\n",
      "[789 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# Function to handle YouTube video scraping with pagination\n",
    "def scrape_videos_with_pagination(max_results=500):\n",
    "    # Initialize an empty list to store the video results\n",
    "    all_videos = []\n",
    "    \n",
    "    # Define the initial API request parameters\n",
    "    # Start with no page token\n",
    "    next_page_token = None  \n",
    "    # Keep track of how many results we've fetched\n",
    "    results_fetched = 0  \n",
    "    \n",
    "    while results_fetched < max_results:\n",
    "        # Make the API request with the nextPageToken for pagination\n",
    "        search_response = youtube.search().list(\n",
    "            part=\"snippet\",\n",
    "            maxResults=50,  # Maximum results per page\n",
    "            pageToken=next_page_token  # Token to fetch the next page\n",
    "        ).execute()\n",
    "        \n",
    "        # Append the fetched videos to the list\n",
    "        all_videos.extend(search_response['items'])\n",
    "        results_fetched += len(search_response['items'])  # Count how many we've fetched\n",
    "        \n",
    "        # Check if there's a next page\n",
    "        next_page_token = search_response.get('nextPageToken')\n",
    "        \n",
    "        # If no nextPageToken, we've reached the end of the results\n",
    "        if not next_page_token:\n",
    "            break\n",
    "\n",
    "    return all_videos\n",
    "\n",
    "def scrape_videos_to_df(filename='yt-crime_data_2.csv'):\n",
    "    # Load the existing data from the CSV file\n",
    "    try:\n",
    "        yt_crime_data = pd.read_csv(filename)\n",
    "    except FileNotFoundError:\n",
    "        # If the file doesn't exist, start with an empty DataFrame\n",
    "        yt_crime_data = pd.DataFrame()  \n",
    "    \n",
    "    # Extract existing video IDs from the 'URL' column \n",
    "    existing_video_ids = yt_crime_data['URL'].apply(lambda x: x.split('v=')[-1]).tolist() if not yt_crime_data.empty else []\n",
    "\n",
    "    # Initialize a list to store new video data\n",
    "    all_videos_data = []\n",
    "\n",
    "    #Call the scrape_videos_with_pagination function to get new videos\n",
    "    videos = scrape_videos_with_pagination(max_results=600)  \n",
    "    #Loop through the scraped videos and check if they already exist in the DataFrame\n",
    "    for video in videos:\n",
    "        # Check if 'id' and 'videoId' are present in the video object\n",
    "        if 'id' in video and 'videoId' in video['id']:\n",
    "            video_id = video['id']['videoId']\n",
    "        else:\n",
    "            # Skip videos that don't have a valid 'videoId'\n",
    "            continue\n",
    "\n",
    "        # Skip videos that are already in the CSV file\n",
    "        if video_id in existing_video_ids:\n",
    "            continue\n",
    "\n",
    "        # Get additional video details\n",
    "        video_details = get_video_details(video_id)\n",
    "\n",
    "        # Collect video data into a dictionary\n",
    "        video_data = {\n",
    "            'Title': video['snippet']['title'],\n",
    "            'URL': f\"https://www.youtube.com/watch?v={video_id}\",\n",
    "            'Likes': video_details['likeCount'],\n",
    "            'Views': video_details['viewCount'],\n",
    "            'Comments Count': video_details['commentCount'],\n",
    "            'Description': video_details['description'],\n",
    "            'Published At': video_details['publishedAt'],\n",
    "            'Channel ID': video_details['channelId'],  # Channel ID\n",
    "            'Channel Title': video_details['channelTitle']  # Channel Title\n",
    "        }\n",
    "\n",
    "        # Add the video data to the list\n",
    "        all_videos_data.append(video_data)\n",
    "\n",
    "    # convert the list of dictionaries to a DataFrame\n",
    "    new_videos_data = pd.DataFrame(all_videos_data)\n",
    "\n",
    "    # append new videos to the existing DataFrame and save to CSV\n",
    "    if not new_videos_data.empty:\n",
    "        yt_crime_data = pd.concat([yt_crime_data, new_videos_data], ignore_index=True)\n",
    "        yt_crime_data.to_csv(filename, index=False)  # Save the updated DataFrame to the CSV file\n",
    "\n",
    "    return yt_crime_data\n",
    "\n",
    "# Get the updated data and display it\n",
    "yt_crime_data = scrape_videos_to_df('yt-crime_data_2.csv')\n",
    "\n",
    "# Print the updated DataFrame (optional)\n",
    "print(yt_crime_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8331b1ce-2471-4847-95e3-e7def5f1a1dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
