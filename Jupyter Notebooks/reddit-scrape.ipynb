{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65125cc8-56a5-468d-8720-4f8735f7cda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting praw\n",
      "  Downloading praw-7.8.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting prawcore<3,>=2.4 (from praw)\n",
      "  Downloading prawcore-2.4.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting update_checker>=0.18 (from praw)\n",
      "  Downloading update_checker-0.18.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in /opt/anaconda3/lib/python3.12/site-packages (from praw) (1.8.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from prawcore<3,>=2.4->praw) (2.32.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2024.8.30)\n",
      "Downloading praw-7.8.1-py3-none-any.whl (189 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.3/189.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading prawcore-2.4.0-py3-none-any.whl (17 kB)\n",
      "Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
      "Installing collected packages: update_checker, prawcore, praw\n",
      "Successfully installed praw-7.8.1 prawcore-2.4.0 update_checker-0.18.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#install praw\n",
    "\n",
    "#%pip install praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "275de2c0-409d-4130-acf1-5bcd8a5a8d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up\n",
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "import praw\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cab05972-aba6-4f30-999b-1042864d5d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#authorize praw\n",
    "reddit = praw.Reddit(\n",
    "    client_id= \"\",\n",
    "    client_secret= \"\" , \n",
    "    user_agent= \"" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60f724c1-d2b9-4367-8794-53a61fcd91a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "redditdev\n",
      "So many books, so little time\n",
      "###### [](#place announcements below)\n",
      "\n",
      "* New Release: [The Sunflower House by Adriana Allegri](https://www.goodreads.com/search?&query=9781250326522)\n",
      "* Check out the [Weekly Recommendation Thread](https://redd.it/1h2jdvt)\n",
      "* Join in the [Weekly \"What Are You Reading?\" Thread!](https://redd.it/1h4sg6l)\n",
      "\n",
      "\n",
      "## [- Subreddit Rules -](/r/books/wiki/rules)[- Message the mods -](http://goo.gl/HXpfgH)[Related Subs](/r/books/wiki/relatedsubreddits)[AMA Info](/r/Books/wiki/amarules)[The FAQ](/r/books/wiki/faq) [The Wiki](/r/books/wiki/index)\n",
      "\n",
      "This is a moderated subreddit. It is our intent and purpose to foster and encourage in-depth discussion about all things related to books, authors, genres or publishing in a safe, supportive environment. If you're looking for help with a personal book recommendation, consult our [Suggested Reading](/r/books/wiki/suggested) page or ask in: /r/suggestmeabook\n",
      "\n",
      "# Quick Rules:\n",
      "\n",
      "1. **Discussion is the goal**  \n",
      "Do not post shallow content. All posts must be directly book related, informative, and discussion focused. \n",
      "\n",
      "2. **Personal conduct**  \n",
      "Please use a civil tone and assume good faith when entering a conversation.\n",
      "\n",
      "3. **Prohibited**  \n",
      "Promotional posts, comments & flairs, media-only posts, personalized recommendation requests incl. ‘Should I read …?’, ‘What’s that book?’ posts, sales links, piracy, plagiarism, low quality book lists, unmarked spoilers (instructions for spoiler tags are in the sidebar), sensationalist headlines, novelty accounts, low effort content. *Please see extended rules for appropriate alternative subreddits, like /r/suggestmeabook, /r/whatsthatbook, etc. or check out our [Related Subreddits](/r/books/wiki/relatedsubreddits).*\n",
      "\n",
      "4. **Encouraged**  \n",
      "We love *original* content and self-posts! Thoughts, discussion questions, epiphanies and interesting links about authors and their work. We also encourage discussion about developments in the book world and we have a flair system. \n",
      "\n",
      "5. **Important**  \n",
      "We don't allow personal recommendation posts. You can ask in our Weekly Recommendation Thread, consult our [Suggested Reading](/r/books/wiki/suggested) or [What to Read](/r/books/wiki/whattoread) page, or post in /r/suggestmeabook.\n",
      "\n",
      "6. **[Click here for the extended rules](/r/Books/wiki/rules)**  \n",
      "Please report any comment that does not follow the rules and remember that mods have the final say.\n",
      "\n",
      "---\n",
      "\n",
      "# Weekly Thread Calendar\n",
      "Day|Frequency|Feature\n",
      ":--:|:--:|:--:\n",
      "Monday|Weekly|[What Books did You Start or Finish Reading this Week?: December 02, 2024](https://redd.it/1h4sg6l)\n",
      "Tuesday|1st of the month|[New Releases: October 2024](https://redd.it/1ftjlb8)\n",
      "Wednesday|Weekly|Literature of the World: [Literature of Slovakia: August 2024](https://redd.it/1f37a75)\n",
      "Thursday|Weekly|Genre Discussion: [Favorite Books about Viruses: December 2024](https://redd.it/1h78njn)\n",
      "Friday|Weekly|[Weekly Recommendation Thread: November 29, 2024](https://redd.it/1h2jdvt)\n",
      "Sunday|Weekly|[Weekly FAQ Thread December 01, 2024: How do I get through an uninteresting book?](https://redd.it/1h41smj)\n",
      "Tues/Sat|Bi-Weekly|[Simple Questions: December 03, 2024](https://redd.it/1h5k2hk)\n",
      "\n",
      "---\n",
      "\n",
      "# Upcoming AMAs\n",
      " | | |\n",
      ":-:|:-:|:-:\n",
      "\n",
      "[The Complete AMA Schedule](/r/books/wiki/amafullschedule)\n",
      "\n",
      "# [Related Subreddits](https://goo.gl/0jV4RT):\n",
      "### [Discussion](https://goo.gl/gc2SkD)\n",
      "### [Genres](https://goo.gl/tqAz83)\n",
      "### [Images](https://goo.gl/coikuy)\n",
      "### [Writing](https://goo.gl/JqC3qe)\n",
      "### [eBooks](https://goo.gl/gxn0Qi)\n",
      "### [Authors](https://goo.gl/VJn5UZ)\n",
      "### [Books/Series](https://goo.gl/DGbvQI)\n",
      "\n",
      "# Other Links:\n",
      "#### Follow our [official Twitter](http://goo.gl/RBcyna) for updates on AMAs and the day's most popular posts!\n",
      "\n",
      "# Spoiler Policy:\n",
      "- Any post with a spoiler in the title will be removed.\n",
      "- Any comment with a spoiler that doesn't use the spoiler code will be removed.\n",
      "- Any user with an extensive history of spoiling books will be banned.\n",
      "- Spoiler tags cover spoilers with black bars that reveal spoilers when a cursor hovers over them They are written as: \\>!spoiler!< with the text \"spoiler\" being your spoiler. Example: >!Hello.!<\n",
      "\n",
      "# [Explanation of our link flairs](/r/books/wiki/flairs)\n",
      "\n",
      "# [Join our /r/bookclub](/r/bookclub)\n",
      "\n",
      "# [Don't forget /new!](/r/books/new)\n",
      "\n",
      "# Filter by Flair\n",
      "> # [AMA](http://goo.gl/94lql6)\n",
      "> # [Weekly Thread](https://www.reddit.com/r/books/search?q=flair%3Aweeklythread&restrict_sr=on&sort=new&t=all)\n",
      "> # [Mod Post](/r/books/search?sort=new&restrict_sr=on&q=flair%3Amod%20post)\n",
      "\n",
      "---\n",
      "\n",
      "> ###### [](#the book banner)\n",
      ">\n",
      "> * [bsct](https://reddit.com/comments/1gzgayd/x/lywkppf)\n",
      "* [](https://reddit.com/comments/1gzgayd/x/lyzqpuz)\n",
      "* [](https://reddit.com/comments/1gzgayd/x/lz95tv7)\n",
      "* [](https://reddit.com/comments/1gzgayd/x/lyws72o)\n",
      "* [](https://reddit.com/comments/1gzgayd/x/lyxb1rk)\n",
      "* [](https://reddit.com/comments/1gzgayd/x/lywlt5p)\n",
      "* [](https://reddit.com/comments/1gzgayd/x/lz6zmql)\n",
      "* [](https://reddit.com/comments/1gzgayd/x/lyzqpuz)\n",
      "* [](https://reddit.com/comments/1gzgayd/x/lyw5z88)\n",
      "* [](https://reddit.com/comments/1gzgayd/x/lyw23fp)\n",
      "* [](https://reddit.com/comments/1gzgayd/x/lyw1yeu)\n",
      "* [](https://reddit.com/comments/1gzgayd/x/lzcez7v)\n",
      "* [](https://reddit.com/comments/1gzgayd/x/lzcez7v)\n",
      "* [](https://reddit.com/comments/1gzgayd/x/lyz22lf)\n",
      "* [](https://reddit.com/comments/1gzgayd/x/lywawwa)\n",
      "* [](https://reddit.com/comments/1gzgayd/x/lyyflz6)\n",
      "* [](https://reddit.com/comments/1gzgayd/x/lywb2a8)\n",
      "* [](https://reddit.com/comments/1gzgayd/x/lyw75qz)\n",
      "* [](https://reddit.com/comments/1gzgayd/x/lz6b9e3)\n",
      "* [](https://reddit.com/comments/1gzgayd/x/lzkjucv)\n",
      "* [](https://reddit.com/comments/1gzgayd/x/lz2aljw)\n",
      "* [](https://reddit.com/comments/1gzgayd/x/lyyjpl9)\n",
      "* [](https://reddit.com/comments/1gzgayd/x/lyxp0mf)\n",
      "* [](https://reddit.com/comments/1gzgayd/x/lyw23fp)\n",
      "* [](https://reddit.com/comments/1gzgayd/x/lywcyse)\n",
      "* [](https://reddit.com/comments/1gzgayd/x/lyw127v)\n",
      "* [](https://reddit.com/comments/1gzgayd/x/lz10467)\n",
      "* [](https://reddit.com/comments/1gzgayd/x/lywro88)\n",
      "* [](https://reddit.com/comments/1gzgayd/x/lzb9ycs)\n",
      "* [](https://reddit.com/comments/1gzgayd/x/lywki4y)\n",
      "\n",
      "\n",
      "\n",
      "##### [ama](https://www.goodreads.com/search?&query=9781250326522)\n",
      "\n",
      "\n",
      "# Check out this week's [Thread Calendar](https://redd.it/1h4sg4k)\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "test_subreddit = reddit.subreddit(\"redditdev\")\n",
    "print(test_subreddit.display_name)\n",
    "\n",
    "book_subreddit = reddit.subreddit(\"books\")\n",
    "print(book_subreddit.title)\n",
    "print(book_subreddit.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "465b6a42-9803-4f27-b47c-889bfaae2575",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pulling from r/washingtondc\n",
    "\n",
    "my_subreddit = \"washingtondc\"\n",
    "submission_headers = ['author', 'created_utc', 'id', \n",
    "                      'is_original_content', 'is_self', \n",
    "                      'link_flair_text', 'locked', 'name', \n",
    "                      'num_comments', 'over_18', 'permalink', \n",
    "                      'score', 'selftext', 'spoiler', 'stickied', \n",
    "                      'subreddit', 'title', 'upvote_ratio', 'url']\n",
    "\n",
    "#Note: 'a' opens the file in append mode to avoid overwriting data\n",
    "with open(\"reddit_test_submission_db.csv\", 'a', \n",
    "          encoding=\"utf-8\", newline='') as f_object:\n",
    "    newposts = reddit.subreddit(my_subreddit).new(limit=None)\n",
    "    for post in newposts:\n",
    "    #Below are all the fields we'll request from PRAW for each post\n",
    "        data = {'author': post.author, 'created_utc': \n",
    "                post.created_utc, 'id': post.id, \n",
    "                'is_original_content': post.is_original_content, \n",
    "                'is_self': post.is_self, 'link_flair_text': \n",
    "                post.link_flair_text, 'locked': post.locked, \n",
    "                'name': post.name, 'num_comments': \n",
    "                post.num_comments, 'over_18': post.over_18, \n",
    "                'permalink': post.permalink, 'score': post.score, \n",
    "                'selftext': post.selftext, 'spoiler': post.spoiler, \n",
    "                'stickied': post.stickied, 'subreddit': \n",
    "                post.subreddit, 'title': post.title, \n",
    "                'upvote_ratio': post.upvote_ratio, 'url': post.url}\n",
    "        dictwriter_object = csv.DictWriter(\n",
    "            f_object, fieldnames=submission_headers)\n",
    "        dictwriter_object.writerow(data)\n",
    "    f_object.close()\n",
    "    \n",
    "#Code below will delete duplicates on successive pulls\n",
    "post_db = pd.read_csv(\"reddit_test_submission_db.csv\", \n",
    "                      names=submission_headers, header=0)\n",
    "post_db.drop_duplicates(subset=\"permalink\", \n",
    "                        keep=\"last\", inplace=True)\n",
    "post_db.to_csv(\"reddit_test_submission_db.csv\", \n",
    "               index=False, chunksize=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37bfe112-2af5-42be-a431-8759e09bd546",
   "metadata": {},
   "outputs": [
    {
     "ename": "ResponseException",
     "evalue": "received 401 HTTP response",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResponseException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m newposts:\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# No more posts available, stop the loop\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m post \u001b[38;5;129;01min\u001b[39;00m newposts:\n\u001b[1;32m     39\u001b[0m     data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthor\u001b[39m\u001b[38;5;124m'\u001b[39m: post\u001b[38;5;241m.\u001b[39mauthor, \n\u001b[1;32m     41\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcreated_utc\u001b[39m\u001b[38;5;124m'\u001b[39m: post\u001b[38;5;241m.\u001b[39mcreated_utc, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m'\u001b[39m: post\u001b[38;5;241m.\u001b[39murl\n\u001b[1;32m     59\u001b[0m     }\n\u001b[1;32m     61\u001b[0m     dictwriter_object \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mDictWriter(f_object, fieldnames\u001b[38;5;241m=\u001b[39msubmission_headers)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/praw/models/listing/generator.py:66\u001b[0m, in \u001b[0;36mListingGenerator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_listing \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_list_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_listing):\n\u001b[0;32m---> 66\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_batch()\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_list_index \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39myielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/praw/models/listing/generator.py:90\u001b[0m, in \u001b[0;36mListingGenerator._next_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exhausted:\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_listing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reddit\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_listing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extract_sublist(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_listing)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_list_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/praw/util/deprecate_args.py:46\u001b[0m, in \u001b[0;36m_deprecate_args.<locals>.wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m     arg_string \u001b[38;5;241m=\u001b[39m _generate_arg_string(_old_args[: \u001b[38;5;28mlen\u001b[39m(args)])\n\u001b[1;32m     40\u001b[0m     warn(\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPositional arguments for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m will no longer be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m supported in PRAW 8.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCall this function with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg_string\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[1;32m     44\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     45\u001b[0m     )\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(_old_args, args)), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/praw/reddit.py:731\u001b[0m, in \u001b[0;36mReddit.get\u001b[0;34m(self, path, params)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;129m@_deprecate_args\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\n\u001b[1;32m    720\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    723\u001b[0m     params: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    724\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    725\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return parsed objects returned from a GET request to ``path``.\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \n\u001b[1;32m    727\u001b[0m \u001b[38;5;124;03m    :param path: The path to fetch.\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;124;03m    :param params: The query parameters to add to the request (default: ``None``).\u001b[39;00m\n\u001b[1;32m    729\u001b[0m \n\u001b[1;32m    730\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 731\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_objectify_request(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGET\u001b[39m\u001b[38;5;124m\"\u001b[39m, params\u001b[38;5;241m=\u001b[39mparams, path\u001b[38;5;241m=\u001b[39mpath)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/praw/reddit.py:514\u001b[0m, in \u001b[0;36mReddit._objectify_request\u001b[0;34m(self, data, files, json, method, params, path)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_objectify_request\u001b[39m(\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    496\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    497\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    498\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run a request through the ``Objector``.\u001b[39;00m\n\u001b[1;32m    499\u001b[0m \n\u001b[1;32m    500\u001b[0m \u001b[38;5;124;03m    :param data: Dictionary, bytes, or file-like object to send in the body of the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m \n\u001b[1;32m    512\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_objector\u001b[38;5;241m.\u001b[39mobjectify(\n\u001b[0;32m--> 514\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[1;32m    515\u001b[0m             data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m    516\u001b[0m             files\u001b[38;5;241m=\u001b[39mfiles,\n\u001b[1;32m    517\u001b[0m             json\u001b[38;5;241m=\u001b[39mjson,\n\u001b[1;32m    518\u001b[0m             method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    519\u001b[0m             params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    520\u001b[0m             path\u001b[38;5;241m=\u001b[39mpath,\n\u001b[1;32m    521\u001b[0m         )\n\u001b[1;32m    522\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/praw/util/deprecate_args.py:46\u001b[0m, in \u001b[0;36m_deprecate_args.<locals>.wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m     arg_string \u001b[38;5;241m=\u001b[39m _generate_arg_string(_old_args[: \u001b[38;5;28mlen\u001b[39m(args)])\n\u001b[1;32m     40\u001b[0m     warn(\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPositional arguments for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m will no longer be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m supported in PRAW 8.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCall this function with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg_string\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[1;32m     44\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     45\u001b[0m     )\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(_old_args, args)), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/praw/reddit.py:963\u001b[0m, in \u001b[0;36mReddit.request\u001b[0;34m(self, data, files, json, method, params, path)\u001b[0m\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ClientException(msg)\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 963\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_core\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[1;32m    964\u001b[0m         data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m    965\u001b[0m         files\u001b[38;5;241m=\u001b[39mfiles,\n\u001b[1;32m    966\u001b[0m         json\u001b[38;5;241m=\u001b[39mjson,\n\u001b[1;32m    967\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    968\u001b[0m         params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    969\u001b[0m         path\u001b[38;5;241m=\u001b[39mpath,\n\u001b[1;32m    970\u001b[0m     )\n\u001b[1;32m    971\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m BadRequest \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m    972\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/prawcore/sessions.py:328\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, path, data, files, json, params, timeout)\u001b[0m\n\u001b[1;32m    326\u001b[0m     json[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapi_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    327\u001b[0m url \u001b[38;5;241m=\u001b[39m urljoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_requestor\u001b[38;5;241m.\u001b[39moauth_url, path)\n\u001b[0;32m--> 328\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request_with_retries(\n\u001b[1;32m    329\u001b[0m     data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m    330\u001b[0m     files\u001b[38;5;241m=\u001b[39mfiles,\n\u001b[1;32m    331\u001b[0m     json\u001b[38;5;241m=\u001b[39mjson,\n\u001b[1;32m    332\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    333\u001b[0m     params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    334\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    335\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m    336\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/prawcore/sessions.py:234\u001b[0m, in \u001b[0;36mSession._request_with_retries\u001b[0;34m(self, data, files, json, method, params, timeout, url, retry_strategy_state)\u001b[0m\n\u001b[1;32m    232\u001b[0m retry_strategy_state\u001b[38;5;241m.\u001b[39msleep()\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_request(data, method, params, url)\n\u001b[0;32m--> 234\u001b[0m response, saved_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[1;32m    235\u001b[0m     data,\n\u001b[1;32m    236\u001b[0m     files,\n\u001b[1;32m    237\u001b[0m     json,\n\u001b[1;32m    238\u001b[0m     method,\n\u001b[1;32m    239\u001b[0m     params,\n\u001b[1;32m    240\u001b[0m     retry_strategy_state,\n\u001b[1;32m    241\u001b[0m     timeout,\n\u001b[1;32m    242\u001b[0m     url,\n\u001b[1;32m    243\u001b[0m )\n\u001b[1;32m    245\u001b[0m do_retry \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m codes[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munauthorized\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/prawcore/sessions.py:186\u001b[0m, in \u001b[0;36mSession._make_request\u001b[0;34m(self, data, files, json, method, params, retry_strategy_state, timeout, url)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_make_request\u001b[39m(\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    176\u001b[0m     data: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    183\u001b[0m     url: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    184\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[Response, \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m]:\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rate_limiter\u001b[38;5;241m.\u001b[39mcall(\n\u001b[1;32m    187\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_requestor\u001b[38;5;241m.\u001b[39mrequest,\n\u001b[1;32m    188\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_header_callback,\n\u001b[1;32m    189\u001b[0m             method,\n\u001b[1;32m    190\u001b[0m             url,\n\u001b[1;32m    191\u001b[0m             allow_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    192\u001b[0m             data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m    193\u001b[0m             files\u001b[38;5;241m=\u001b[39mfiles,\n\u001b[1;32m    194\u001b[0m             json\u001b[38;5;241m=\u001b[39mjson,\n\u001b[1;32m    195\u001b[0m             params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    196\u001b[0m             timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    197\u001b[0m         )\n\u001b[1;32m    198\u001b[0m         log\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    199\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponse: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m bytes) (rst-\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m:rem-\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m:used-\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m ratelimit) at \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    200\u001b[0m             response\u001b[38;5;241m.\u001b[39mstatus_code,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m             time\u001b[38;5;241m.\u001b[39mtime(),\n\u001b[1;32m    206\u001b[0m         )\n\u001b[1;32m    207\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/prawcore/rate_limit.py:46\u001b[0m, in \u001b[0;36mRateLimiter.call\u001b[0;34m(self, request_function, set_header_callback, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Rate limit the call to ``request_function``.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03m:param request_function: A function call that returns an HTTP response object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m \n\u001b[1;32m     44\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelay()\n\u001b[0;32m---> 46\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m set_header_callback()\n\u001b[1;32m     47\u001b[0m response \u001b[38;5;241m=\u001b[39m request_function(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(response\u001b[38;5;241m.\u001b[39mheaders)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/prawcore/sessions.py:282\u001b[0m, in \u001b[0;36mSession._set_header_callback\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_header_callback\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_authorizer\u001b[38;5;241m.\u001b[39mis_valid() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_authorizer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrefresh\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 282\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_authorizer\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAuthorization\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbearer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_authorizer\u001b[38;5;241m.\u001b[39maccess_token\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m}\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/prawcore/auth.py:378\u001b[0m, in \u001b[0;36mReadOnlyAuthorizer.refresh\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_scopes:\n\u001b[1;32m    377\u001b[0m     additional_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscope\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_scopes)\n\u001b[0;32m--> 378\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request_token(grant_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclient_credentials\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39madditional_kwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/prawcore/auth.py:155\u001b[0m, in \u001b[0;36mBaseAuthorizer._request_token\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    153\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_authenticator\u001b[38;5;241m.\u001b[39m_requestor\u001b[38;5;241m.\u001b[39mreddit_url \u001b[38;5;241m+\u001b[39m const\u001b[38;5;241m.\u001b[39mACCESS_TOKEN_PATH\n\u001b[1;32m    154\u001b[0m pre_request_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 155\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_authenticator\u001b[38;5;241m.\u001b[39m_post(url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdata)\n\u001b[1;32m    156\u001b[0m payload \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m payload:  \u001b[38;5;66;03m# Why are these OKAY responses?\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/prawcore/auth.py:59\u001b[0m, in \u001b[0;36mBaseAuthenticator._post\u001b[0;34m(self, url, success_status, **data)\u001b[0m\n\u001b[1;32m     51\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_requestor\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     53\u001b[0m     url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     56\u001b[0m     headers\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m     57\u001b[0m )\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m success_status:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResponseException(response)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[0;31mResponseException\u001b[0m: received 401 HTTP response"
     ]
    }
   ],
   "source": [
    "#trying to scrape reddit posts until 2000 posts\n",
    "import praw\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize PRAW instance with your credentials\n",
    "reddit = praw.Reddit(client_id='your_client_id', \n",
    "                     client_secret='your_client_secret', \n",
    "                     user_agent='your_user_agent')\n",
    "\n",
    "my_subreddit = \"washingtondc\"\n",
    "submission_headers = ['author', 'created_utc', 'id', \n",
    "                      'is_original_content', 'is_self', \n",
    "                      'link_flair_text', 'locked', 'name', \n",
    "                      'num_comments', 'over_18', 'permalink', \n",
    "                      'score', 'selftext', 'spoiler', 'stickied', \n",
    "                      'subreddit', 'title', 'upvote_ratio', 'url']\n",
    "\n",
    "# Initialize variables for pagination\n",
    "last_post_id = None  # For paginating (storing the id of the last post pulled)\n",
    "post_count = 0  # Counter to track the number of posts fetched\n",
    "max_posts = 2000  # The maximum number of posts you want to fetch\n",
    "\n",
    "with open(\"reddit_test_submission_db.csv\", 'a', \n",
    "          encoding=\"utf-8\", newline='') as f_object:\n",
    "    \n",
    "    while post_count < max_posts:\n",
    "        if last_post_id:\n",
    "            # Fetch posts after the last post pulled using `after`\n",
    "            newposts = reddit.subreddit(my_subreddit).new(limit=100, params={'after': last_post_id})\n",
    "        else:\n",
    "            # For the first pull, don't use `after`\n",
    "            newposts = reddit.subreddit(my_subreddit).new(limit=100)\n",
    "        \n",
    "        if not newposts:\n",
    "            break  # No more posts available, stop the loop\n",
    "\n",
    "        for post in newposts:\n",
    "            data = {\n",
    "                'author': post.author, \n",
    "                'created_utc': post.created_utc, \n",
    "                'id': post.id, \n",
    "                'is_original_content': post.is_original_content, \n",
    "                'is_self': post.is_self, \n",
    "                'link_flair_text': post.link_flair_text, \n",
    "                'locked': post.locked, \n",
    "                'name': post.name, \n",
    "                'num_comments': post.num_comments, \n",
    "                'over_18': post.over_18, \n",
    "                'permalink': post.permalink, \n",
    "                'score': post.score, \n",
    "                'selftext': post.selftext, \n",
    "                'spoiler': post.spoiler, \n",
    "                'stickied': post.stickied, \n",
    "                'subreddit': post.subreddit, \n",
    "                'title': post.title, \n",
    "                'upvote_ratio': post.upvote_ratio, \n",
    "                'url': post.url\n",
    "            }\n",
    "\n",
    "            dictwriter_object = csv.DictWriter(f_object, fieldnames=submission_headers)\n",
    "            dictwriter_object.writerow(data)\n",
    "            \n",
    "            # Set the last post's id for the next iteration\n",
    "            last_post_id = post.id\n",
    "            post_count += 1  # Increment post count after each post\n",
    "            print(f\"Fetched {post_count} posts\")\n",
    "\n",
    "        # Stop the loop if we've fetched the maximum number of posts\n",
    "        if post_count >= max_posts:\n",
    "            print(f\"Reached {max_posts} posts. Stopping the fetch.\")\n",
    "            break\n",
    "\n",
    "    f_object.close()\n",
    "\n",
    "# Code to delete duplicates (based on permalink) after the pull\n",
    "post_db = pd.read_csv(\"reddit_test_submission_db.csv\", \n",
    "                      names=submission_headers, header=0)\n",
    "post_db.drop_duplicates(subset=\"permalink\", \n",
    "                        keep=\"last\", inplace=True)\n",
    "post_db.to_csv(\"reddit_test_submission_db.csv\", \n",
    "               index=False, chunksize=1000)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae79d6a9-b1eb-48c3-a43f-877fffb1e7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This block creates list of submissions for which we want comments\n",
    "comment_headers = ['author', 'body', 'created_utc', \n",
    "                   'distinguished', 'edited', 'id', \n",
    "                   'is_submitter', 'link_id', 'parent_id', \n",
    "                   'permalink', 'saved', 'score', 'stickied', \n",
    "                   'submission', 'subreddit', 'subreddit_id']\n",
    "with open('reddit_test_comment_db.csv', 'a') as comment_file:\n",
    "    comments_db = pd.read_csv('reddit_test_comment_db.csv', \n",
    "                              usecols=[\"submission\"], \n",
    "                              names=comment_headers)\n",
    "    comment_file.close()\n",
    "submission_db = pd.read_csv(\"reddit_test_submission_db.csv\", \n",
    "                            usecols=[\"created_utc\", \"id\"])\n",
    "#Filter down to submissions for which we don't yet have comments\n",
    "comments_set = set(comments_db[\"submission\"])\n",
    "#259,200 is three days worth of seconds\n",
    "try:\n",
    "    time_cutoff = max([created_utc for post_id, created_utc in \n",
    "         zip(submission_db.id, submission_db.created_utc) \n",
    "         if post_id in comments_set]) - 259200\n",
    "except:\n",
    "    time_cutoff = submission_db[\"created_utc\"].min()\n",
    "submissions_to_pull = submission_db.loc[submission_db\n",
    "                                        [\"created_utc\"] >= \n",
    "                                        time_cutoff, \"id\"]\n",
    "#This block pulls all comments for the list of submissions we have identified\n",
    "with open(\"reddit_test_comment_DB.csv\", 'a', \n",
    "          encoding=\"utf-8\", newline='') as f_object:\n",
    "    for row in submissions_to_pull:\n",
    "        submission = reddit.submission(id=row)\n",
    "        submission.comments.replace_more(limit=None)\n",
    "        for comment in submission.comments.list():\n",
    "            data = {'author': comment.author, 'body': \n",
    "                    comment.body, 'created_utc': \n",
    "                    comment.created_utc, 'distinguished': \n",
    "                    comment.distinguished, 'edited': \n",
    "                    comment.edited, 'id': comment.id, \n",
    "                    'is_submitter': comment.is_submitter, \n",
    "                    'link_id': comment.link_id, 'parent_id': \n",
    "                    comment.parent_id, 'permalink': \n",
    "                    comment.permalink, 'saved': comment.saved, \n",
    "                    'score': comment.score, 'stickied': \n",
    "                    comment.stickied, 'submission': \n",
    "                    comment.submission, 'subreddit': \n",
    "                    comment.subreddit, \n",
    "                    'subreddit_id': comment.subreddit_id}\n",
    "            dictwriter_object = csv.DictWriter(f_object, \n",
    "                                               fieldnames=\n",
    "                                               comment_headers)\n",
    "            dictwriter_object.writerow(data)\n",
    "    f_object.close()\n",
    "    \n",
    "#Now drop duplicate rows\n",
    "comment_db = pd.read_csv(\"reddit_test_comment_DB.csv\", \n",
    "                         names=comment_headers, header=0)\n",
    "#First drop duplicates that are not edited, keep the last pull\n",
    "comment_db.drop_duplicates(subset=[\"permalink\", \"body\", \"id\"],\n",
    "                           keep = \"last\", inplace=True)\n",
    "#Then drop duplicates that have been edited, keep the first pull\n",
    "comment_db.drop_duplicates(subset=\"permalink\", \n",
    "                           keep = \"first\", inplace=True)\n",
    "comment_db.to_csv(\"reddit_test_comment_DB.csv\", \n",
    "                  index=False, chunksize=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
